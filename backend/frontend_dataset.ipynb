{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same as other notebook this is for data cleaning and producing the frontend dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "title_akas_df = pd.read_csv('data/title.akas.tsv', sep='\\t')\n",
    "title_basics_df = pd.read_csv('data/title.basics.tsv', sep='\\t')\n",
    "#title_ratings_df = pd.read_csv('data/title.ratings.tsv', sep='\\t')\n",
    "#title_principals_df = pd.read_csv('data/title.principals.tsv', sep='\\t')\n",
    "#name_df = pd.read_csv('data/name.basics.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data to include only movies\n",
    "movies_df = title_basics_df[title_basics_df['titleType'] == 'movie'].copy()\n",
    "\n",
    "# drop adult movies\n",
    "movies_df = movies_df[movies_df['isAdult'] == 0]\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns that are not needed\n",
    "movies_df.drop(columns=['titleType', 'isAdult', 'endYear',], inplace=True)\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.to_csv('frontendData/frontend_movies.csv')\n",
    "movies_df.to_json('frontendData/frontend_movies.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import threading\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Load JSON\n",
    "with open(\"frontendData/frontend_movies.json\", \"r\") as f:\n",
    "    data = json.load(f)  # data is a LIST, not a dictionary\n",
    "\n",
    "from webscraping import movie_api_wrapper as ib\n",
    "parser = ib.IMDbParser()\n",
    "\n",
    "# Thread-safe counter\n",
    "counter = 0\n",
    "lock = threading.Lock()\n",
    "total = max(3, len(data))  # Only testing with 3 items initially using min(3, len(data))\n",
    "\n",
    "# Function to Upload a Single Document\n",
    "def upload_document(index, item):\n",
    "    global counter\n",
    "    try:\n",
    "        time.sleep(random.uniform(0.1, 3.0))  # Random delay\n",
    "\n",
    "        doc_id = item.get(\"tconst\")  # Use \"tconst\" as the document ID\n",
    "\n",
    "        if doc_id:\n",
    "            results = parser.search(doc_id)\n",
    "            if results:  # Ensure results is not empty\n",
    "                data[index]['cast'] = results[0].get('cast', []) if results[0].get('cast', []) else []\n",
    "                data[index]['poster'] = results[0].get('poster', {}).get('url', '') if results[0].get('poster', {}).get('url', '') else ''\n",
    "\n",
    "        with lock:  # Ensure thread-safe counter update\n",
    "            counter += 1\n",
    "            print(f\"({counter} out of {total} done so far)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        counter += 1\n",
    "        print(f\"Unkown error for {doc_id}: {e}\")\n",
    "        print(f\"({counter} out of {total} done so far)\")\n",
    "\n",
    "\n",
    "# Use Threading for Faster Retrieval\n",
    "threads = []\n",
    "for index, item in enumerate(data[:total]):  # Limit to `total`\n",
    "    thread = threading.Thread(target=upload_document, args=(index, item))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "# Save updated JSON\n",
    "with open('frontendData/complete_frontend_movies.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "print(\"Dumped new JSON with progress tracking\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload to firebase \n",
    "#!pip install firebase-admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore\n",
    "import json\n",
    "\n",
    "# appareantly reading through stackoverflow there is no \"upload a JSON to firestore\" function\n",
    "# so we have to read the JSON file and upload it to firestore manually\n",
    "cred = credentials.Certificate(\"\")\n",
    "#firebase_admin.initialize_app(cred)\n",
    "\n",
    "db = firestore.client()\n",
    "\n",
    "# load json\n",
    "with open(\"frontendData/frontend_movies.json\", \"r\") as f:\n",
    "    data = json.load(f)  # data is a LIST, not a dictionary\n",
    "\n",
    "#upload\n",
    "collection_name = \"moviedata\" \n",
    "\n",
    "for item in data:  # Iterate over the list using tconst\n",
    "    doc_id = item.get(\"tconst\")  \n",
    "    if doc_id:\n",
    "        db.collection(collection_name).document(doc_id).set(item)\n",
    "        print(f\"Uploaded document: {doc_id}\")\n",
    "\n",
    "print(\"uplaoded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import threading\n",
    "\n",
    "db = firestore.client()\n",
    "\n",
    "# load json\n",
    "with open(\"frontendData/frontend_movies.json\", \"r\") as f:\n",
    "    data = json.load(f)  # data is a LIST, not a dictionary\n",
    "# Find the index of the last uploaded document\n",
    "\n",
    "from webscraping import movie_api_wrapper as ib\n",
    "parser = ib.IMDbParser()\n",
    "\n",
    "\n",
    "# Function to Upload a Single Document\n",
    "def upload_document(item):\n",
    "    try:\n",
    "        doc_id = item.get(\"tconst\")  # Use \"tconst\" as the document ID\n",
    "        \n",
    "        if doc_id:\n",
    "            db.collection(\"moviedata\").document(doc_id).set(item)\n",
    "            print(f\"Uploaded document: {doc_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading {doc_id}: {e}\")\n",
    "        \n",
    "        \n",
    "#Use Threading for Faster Uploads\n",
    "threads = []\n",
    "for item in data:\n",
    "    thread = threading.Thread(target=upload_document, args=(item,))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(\"JSON Upload Complete with Threading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
